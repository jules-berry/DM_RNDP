\documentclass[a4paper,12pt,french]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{caption}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage[document]{ragged2e}
\usepackage{hyperref}
\usepackage{etoolbox}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{epstopdf}
\usepackage[nottoc, notlof, notlot]{tocbibind}
\usepackage{fourier}

%opening
\title{DM RNDP}
\date{}
\author{Jules Berry, Thomas Poisson}

\theoremstyle{definition}
\newtheorem{definition}{D\'efinition}[section]
\AtEndEnvironment{definition}{\hfill $\square$}
\newtheorem{remarque}{Remarque}[section]

\theoremstyle{theorem}
\newtheorem{prop}{Proposition}[section]
\newtheorem{thm}{Th\'eor\`eme}[section]
\newtheorem{lemme}{Lemme}[section]
\newtheorem{corollaire}{Corollaire}[section]


\renewcommand\qedsymbol{$\blacksquare$}
\newcommand{\T}{\mathbb{T}}
\newcommand{\norm}[2]{\lVert{#1}\rVert_{#2}}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\Lp}[1]{L^{#1}(\T)}
\newcommand{\C}{\mathcal{C}}
\newcommand{\module}[1]{\left \lvert #1 \right \rvert}
\newcommand{\scalaire}[2]{\left \langle {#1},\ {#2} \right \rangle}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\scalaireo}[2]{\left \langle {#1},\ {#2} \right \rangle_{\omega}}



\begin{document}

\maketitle

\justify

\tableofcontents

\newpage

\section{Préliminaires}
\subsection{Question 1}
 \item On cherche une fonction $u \in \C^2([-1,1])$ telle que
 \begin{equation}\label{eq:problème_1}
  \begin{cases}
   -(\alpha(x) u'(x))' + \gamma(x)u(x) = f(x) \quad \forall x \in ] -1, 1[, \\
   u(-1) = c_1,\ u(1) = c_2
  \end{cases}.
 \end{equation}

 Soit $u$ un solution de ce problème et on pose
 \[
  v(x) = u(x) - c_1 \frac{x - 1}{2} - c_2 \frac{x+1}{2}
 \]
cette fonction est alors aussi $\C^2([-1,1])$ et on a de plus
\[
 v'(x) = u'(x) - \frac{c_1 + c_2}{2}, \quad v''(x) = u''(x).
\]
En injectant cette fonction dans l'EDO de \eqref{eq:problème_1} on a
\begin{align*}
 -(\alpha(x)v'(x))' + \gamma(x)v(x) &= -\alpha'(x)v'(x) - \alpha(x)v''(x) + \gamma(x)v(x) \\
 &= -(\alpha(x)u'(x))' + \frac{c_1 + c_2}{2}\alpha'(x) + \gamma(x)u(x) - \gamma(x)\left (c_1 \frac{x-1}{2} + c_2 \frac{x+1}{2} \right)
\end{align*}
On a donc que la fonction $v$ est solution du problème
\begin{equation}\label{eq:problème_2}
 \begin{cases}
  -(\alpha(x)v'(x))' + \gamma(x)v(x) = \tilde f(x) \\
  v(-1) = v(1) = 0
 \end{cases}
\end{equation}
où $\tilde f(x) = f(x) + \gamma(x)\left(c_1 \frac{x-1}{2} + c_2 \frac{x+1}{2}\right) - \frac{c_1 + c_2}{2}\alpha'(x)$.

De plus il est clair que $v(-1) = v(1) = 0$ et comme $f \in L^2(]-1,1[)$ , $\alpha \in \C^1([-1,1])$ et $\gamma \in L^\infty ([-1,1]) \subset L^2(]-1,1[)$ on a aussi $\tilde f \in L^2([-1,1])$.

On voit alors que le problème \eqref{eq:problème_2} est de la forme souhaitée. De plus si $v$ est une solution de ce problème et en posant $w(x) = v(x) + c_1 \frac{x - 1}{2} + c_2 \frac{x+1}{2}$, on peut voir que $w$ est une solution de \eqref{eq:problème_1}. On a donc montré que l'étude de ce dernier se ramène à l'étude de \eqref{eq:problème_2}.

\subsection{Question 2}

On pose $u = \rho v$ où $\rho : x \in [-1,1] \mapsto \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right)$.
Alors si $u$ est une solution de l'EDO
\begin{equation}
 -(\alpha u')' + \beta u' + \gamma u = f
\end{equation}
On remarque alors que
\begin{align*}
 \rho'(x) &= \frac{d}{dx} \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right) = \frac{\beta(x)}{2\alpha(x)} \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right) \\
 &= \frac{\beta(x)}{2\alpha(x)} \rho(x).
\end{align*}
Et par suite
\[
 \rho'' = \frac{1}{2} \left ( \frac{\beta' \alpha - \beta \alpha'}{\alpha^2}\rho + \frac{\beta}{\alpha} \rho'\right) = \frac{\beta' \alpha + 2 \beta^2 - \beta \alpha'}{2 \alpha^2}\rho.
\]

En réétudiant l'EDO on trouve donc
\begin{align*}
 -(\alpha u')' + \beta u' + \gamma u &= - \alpha' (\rho' v + \rho v') - \alpha ( \rho '' v + 2 \rho' v' + \rho v'') + \beta (\rho' v + \rho v') + \gamma \rho v \\
 &= \rho \left ( -\frac{\alpha' \beta v}{\alpha} - \alpha' v' - \frac{\beta' v}{2} - \frac{\beta^2 v}{\alpha} + \frac{\beta \alpha' v }{\alpha} - \beta v' - \alpha v'' + \frac{\beta^2 v}{\alpha} + \beta v' + \gamma v \right) = f
\end{align*}
Par définition de la fonction de $\rho$ celle-ci est strictement positive et on peut donc diviser par $\rho$ dans l'équation. Alors en simplifiant le membre de gauche on trouve
\[
 - \alpha' v' - \alpha v'' - \frac{1}{2} \beta' v +\gamma v = \frac{f}{\rho}.
\]
Alors en posant $\delta = \gamma - \frac{1}{2}\beta'$ et $g = \frac{f}{\rho}$. On trouve donc
\begin{equation}\label{eq:EDO_1}
 -(\alpha v')' + \delta v = g.
\end{equation}
On remarque au passage que nous avons supposé que la fonction $\beta$ était au moins $\C^1$.

\subsection{Question 3}

On considère l'EDO $-(\alpha u')' + \gamma u = f$ sur $[a,b]$. En posant
\[
 h : x \in [-1,1] \mapsto a \frac{x-1}{2} + b \frac{x+1}{2}
\]
et on considérant la fonction $v : x \in [-1,1] \mapsto u \circ h(x)$ on trouve que $v(-1) = u(a)$ et $v(1) = u(b)$. De plus en posant aussi $\tilde \alpha = \alpha \circ h$, $\tilde \gamma = \frac{b - a}{2} \gamma \circ h$ on a en supposant que $u$ est une solution de l'EDO
\begin{align*}
 -(\tilde \alpha(x) v'(x))' + \tilde \gamma(x) v(x) &= -(\alpha(h(x))(u(h(x)))')' + \frac{a + b}{2} \gamma(h(x))v(h(x)) \\
 &= -\frac{a + b}{2}( \alpha (h(x)) u'(h(x)))' + \frac{a + b}{2} \gamma(h(x)) u(h(x)) \\
 &= \frac{a+b}{2} f(h(x)).
\end{align*}
On peut alors poser $\tilde f(x) = \frac{a+b}{2} f \circ h (x)$ et on a alors que $v$ est solution de la nouvelle EDO
\[
 -(\tilde \alpha(x) v'(x))' + \tilde \gamma (x) u(x) = \tilde f(x).
\]
Comme la fonction $h$ est un polynôme de degrés un elle est bijective de $[-1,1]$ dans $[a,b]$. Alors si $v$ est solution de la dernière EDO on peut inverser la construction en posant $u =h^{-1} \circ v$ on voit que $u$ est solution de la première EDO.

\subsection{Quastion 4}

On cherche ici une solution $u \in H^2(]-1,1[)$ de

\begin{equation}\label{eq:problem_3}
 \begin{cases}
  -(\alpha(x) u'(x))' + \gamma(x) u(x) = f(x) \quad \forall x \in ]-1,1[ \\
  u(-1) = u(1) = 0
 \end{cases}.
\end{equation}


On commence par trouver une solution à la formulation variationnelle de \eqref{eq:problem_3} dans l'espace $H_0^1(]-1,1[)$. Soit $\phi \in H_0^1(]-1,1[)$ on a alors
\[
 -\int _{-1}^1 (\alpha(t)u'(t))' \phi(t)\ dt + \int _{-1}^1 \gamma(t) u(t) \phi(t) \ dt = \int _{-1}^1 f(t) \phi(t) \ dt.
\]
En intégrant par parties on trouve
\[
 \int _{-1}^1 (\alpha(t)u'(t)) \phi'(t)\ dt + \int _{-1}^1 \gamma(t) u(t) \phi(t) \ dt = \int _{-1}^1 f(t) \phi(t) \ dt.
\]

On cherche ensuite à appliquer le théorème de Lax-Milgram dans $H_0^1(]-1,1[)$. Pour cela on pose $a$ la forme bilinéaire
\[
 a : (\phi,\psi) \in (H_0^1(]-1,1[))^2 \mapsto \int _{-1}^1 (\alpha(t)\phi'(t)) \psi'(t)\ dt + \int _{-1}^1 \gamma(t) \phi(t) \psi(t) \ dt
\]
et $l$ la forme linéaire
\[
 l : \phi \in H_0^1(]-1,1[) \mapsto \int _{-1}^1 f(t) \phi(t) \ dt.
\]

On a alors
\[
 \module{\langle l, \phi \rangle} \leq  \int _{-1}^1 \module{f(t) \phi(t)} \ dt \leq \norm{f}{L^2}\norm{\phi}{L^2} \leq \norm{f}{L^2}\norm{\phi}{H^1}
\]
ce qui montre que $l$ est une forme linéaire continue sur $H_0^1(]-1,1[)$.
De plus on a aussi
\begin{align*}
 \module{a(\phi,\psi)} &\leq \int _{-1}^1 \module{\alpha(t)\phi'(t) \psi'(t)} \ dt + \int _{-1}^1 \module{\gamma(t) \phi(t) \psi(t)} \ dt \\
 & \leq \norm{\alpha}{L^\infty} \int _{-1}^1 \module{\phi'(t) \psi'(t)} \ dt + \norm{\gamma}{L^\infty}\int _{-1}^1 \module{\phi(t) \psi(t)} \ dt \\
 & \leq M \left ( \norm{\phi'}{L^2} \norm{\psi'}{L^2} + \norm{\phi}{L^2} \norm{\psi}{L^2} \right ) \\
 & \leq M \sqrt{\norm{\phi}{L^2}^2 + \norm{\phi'}{L^2}^2} \sqrt {\norm{\psi}{L^2}^2 + \norm{\psi'}{L^2}^2} \\
 & = M \norm{\phi}{H^1}\norm{\psi}{H^1}
\end{align*}
Ce qui montre que $a$ est une forme bilinéaire continue sur $H_0^1(]-1,1[)$.

Il reste donc a montrer que $a$ est coercive. Pour cela il suffit de voir que
\[
 a(\phi,\phi) = \int_{-1}^1 \alpha(t) \module{\phi'(t)}^2\ dt + \int_{-1}^1 \gamma(t) \module{\phi(t)}^2\ dt \geq \alpha_0 \norm{\phi'}{L^2}^2
\]
et par l'inégalité de Poincaré on sait que la norme $\phi \mapsto \norm{\phi'}{L^2}$ est équivalente à la norme usuelle de $H_0^1(]-1,1[)$.

On peut à présent appliquer le théorème de Lax-Milgram pour obtenir l'existence d'une unique solution $u$ à la formulation variationnelle du problème \eqref{eq:problem_3} dans $H_0^1(]-1,1[)$. Il nous faut à présent montrer que cette solution est dans $H_0^2(]-1,1[)$, c'est-à-dire qu'elle admet une dérivée faible seconde qui soit dans $L^2(]-1,1[)$. On cherche donc une fonction $g \in L^2(]-1,1[)$ qui vérifie
\[
 - \int u \phi' = \int g \phi
\]
pour toute fonction test $\phi \in \mathcal{D}(]-1,1[)$.

Comme $u$ est solution de la formulation variationnelle du problème, on sait déjà que
\[
 \int _{-1}^1 (\alpha(t)u'(t)) \phi'(t)\ dt = \int _{-1}^1 (f(t) - \gamma(t) u(t)) \phi(t) \ dt.
\]
Ce qui signifie que la fonction $\alpha u'$ admet comme dérivée faible $\gamma u -f$ qui se trouve être dans $L^2$. On a donc que $\alpha u \in H^1$. Or on sait que $(\alpha u')' = \alpha' u' + \alpha u''$. Ce qui donne
\[
 u'' = \frac{\gamma u - \alpha' u' - f}{\alpha}
\]
qui a bien un sens car $\alpha$ est supposée strictement positive.De plus peut voir que $u''$ est dans $L^2$. Ce qui montre que la solution $u$ de \eqref{eq:problem_3} est dans $H^2$.

\subsection{Question 5}

On se donne la fonction
\[
 \omega (x) = \frac{1}{\sqrt{1 - x^2}}
\]
et on cherche à montrer que la forme bilinéaire
\[
 \scalaire{\phi}{\psi}_\omega = \int_{-1}^1 \phi(x) \psi(x) \omega(x) \ dx
\]
définit un produit scalaire sur $\mathcal{C}^0([-1,1])$.

La forme bilinéaire $\scalaire{\cdot}{\cdot}\omega$ est clairement symétrique et on a
\begin{align*}
 \scalaire{\phi}{\phi}_\omega = \int \frac{\module{\phi(x)}^2}{\sqrt{1-x^2}} \ dx \geq 0
\end{align*}
et on remarque que $\scalaire{\phi}{\phi}_\omega = 0$ si, et seulement si, $\phi = 0$ car $\omega$ est strictement positive sur $]-1,1[$.
Il reste juste à monter que l'intégrale est bien définie. Or on a
\begin{align*}
 \module{\scalaire{\phi}{\psi}_\omega} \leq \norm{\phi}{\infty} \norm{\psi}{\infty} \int_{-1}^1 \frac{1}{\sqrt{1 - x^2}}\ dx.
\end{align*}

Or on a
\begin{align*}
 \int_{-1}^1 \frac{1}{\sqrt{1 - x^2}}\ dx &= 2 \int_0^1 \frac{1}{\sqrt{1-x} \sqrt{1+x}}\ dx \\
 & \leq 2 \int_0^1 \frac{1}{\sqrt{1-x}}\ dx < + \infty.
\end{align*}
Ce qui montre que $\scalaire{\cdot}{\cdot}_\omega$ définit un produit scalaire.


\section{Polynômes de Tchebychev}

\subsection{Question 1}

 On montre que pour tout $n \in \N$ in existe une unique polynôme $T_n \in \R_n[X]$ tel que $T_n(\cos(\omega)) = \cos(n\omega)$. On procède par récurrence en commençant par remarquer que que l'on a clairement $T_0(X) = 1$ et $T_1(X) = X$. Ensuite on a
\begin{align*}
 (\cos(\omega))^n &= \left ( \frac{e^{i\omega} + e^{-i\omega}}{2} \right ) ^n = 2^{-n} \sum_{k=0}^n \binom{n}{k} e^{ik\omega}e^{-i(n-k)\omega} \\
 &= 2^{-n} \sum_{k=0}^n \binom{n}{k} e^{i(2k-n)\omega}.
\end{align*}

On note de plus que $\binom{n}{k} = \binom{n}{n-k} = \frac{n!}{k!(n-k)!}$ et on note alors cette quantité $h_k^n$. On a alors
\begin{align*}
 (\cos(\omega))^n &= 2^{-n} \sum_{k=0}^{\lfloor n/2 \rfloor } h_k^n \left ( e^{i(2k -n) \omega} + e^{i(n - 2k)\omega} \right) \\
 &= 2^{-(n-1)} \sum_{k=0}^{\lfloor n/2 \rfloor } h_k^n \cos((n - 2k)\omega)).
\end{align*}

On note à présent $m = \lfloor n/2 \rfloor$ et d'après l'hypothèse de récurrence pour tout $k \in \{1, \dots, m\}$ il existe un polynôme $T_{n-2k}(X)$ tel que $T_{n - 2k}(\cos(\omega)) = \cos((n - 2k)\omega)$. On peut alors poser
\[
 T_n(X) = 2^{(n-1)} X^n - \sum_{k=1}^m  \widetilde{h_k^n} T_{n-2k}(X).
\]
où on a noté $\widetilde{h_k^n} = \begin{cases}
                                   0 \quad \textnormal{si } h_k^n = 0 \\
                                   \frac{1}{h_k^n} \quad \textnormal{sinon}
                                  \end{cases}$.

Pour l'unicité, si on suppose qu'il existe un autre polynôme $R_n(X)$ vérifiant que $R_n(\cos(\omega)) = \cos(n\omega)$. Alors pour tout $\omega \in [0,2\pi]$ $\cos(\omega)$ est une racine du polynôme $T_n - R_n$ ce qui implique $T_n - R_n = 0$.

\subsection{Question 2}

\paragraph{a.} On montre que $T_{n + 2}(x) + T_n(x) = 2xT_{n+1}(x)$. Pour cela on a
\begin{align*}
 T_{n + 2}(cos(\omega)) + T_n(\cos(\omega)) &= \cos((n+2)\omega) + \cos(n\omega) \\
 &= \frac{e^{i((n+2)\omega)} + e^{-i((n+2)\omega)} + e^{in\omega} + e^{in\omega}}{2} \\
 &= \frac{e^{i((n+1)\omega)}(e^{in\omega} + e^{-in\omega}) + e^{-i((n+1)\omega)}(e^{in\omega} + e^{-in\omega})} {2} \\
 &= 2\cos(\omega)\cos((n+1)\omega) \\
 &= 2\cos(\omega) T_{n+1}(\cos(\omega)).
\end{align*}
Comme de plus $\cos$ est une bijection de $[0,2\pi]$ dans $[-1,1]$ on a montré que pour tout $x \in [-1,1]$ on a $T_{n + 2}(x) + T_n(x) = 2xT_{n+1}(x)$.

\paragraph{b.} La relation $T_n(\cos(x)) = \cos(nx)$ nous donne nécessairement $T_0(x) = 1$ et $T_1 (x) = x$. En utilisant la question \emph{a.} on trouve alors 
\begin{align*}
 T_2(x) &= 2x T_1(x) - T_0(x) = 2x^2 - 1 \\
 T_3(x) &= 2xT_2(x) - T_1(x) = 2x(2x^2 -1) - x = 4x^3 - 3x.
\end{align*}

\paragraph{c.} On montre que pour tout $n \geq 2$ et pour tout $x \in [-1,1]$ on a 
\begin{equation}\label{eq:eq1}
 2 T_n(x) = \frac{1}{n+1} T_{n+1}'(x) - \frac{1}{n-1}T_{n-1}'(x).
\end{equation}


On a 
\begin{align*}
 T_{n+1}' &= \frac{n+1}{\sqrt{1-x^2}}\sin((n-1)\arccos(c)) \quad \textnormal{et} \\
 T_{n-1}'(x) &= \frac{n-1}{\sqrt{1 - x^2}}\sin((n-1)\arccos(x)),
\end{align*}
on a donc 
\begin{align*}
 \frac{1}{n+1}T_{n+1}'(x) &- \frac{1}{n-1}T_{n-1}'(x) = \frac{1}{\sqrt{1-x^2}} \left[ \sin((n+1)\arccos(x)) - \sin((n-1)\arccos(x)) \right ] \\
 &= \frac{1}{\sqrt{1-x^2}}  [ \sin(n \arccos(x))x + \sqrt{1-x^2} \cos(n\arccos(x)) \\ & \quad - \sin(n\arccos(x))x + \sqrt{1-x^2} \cos(n\arccos(x))  ] \\
 &= 2 \cos (n\arccos(x)) = 2 T_n(x)
\end{align*}
Ce qui montre la relation \eqref{eq:eq1}.

\paragraph{d.} On montre les deux affirmations simultanément par récurrence. On vérifie facilement que l'on a $T_1'(x) = 1 = T_0(x) = 2\sum^\star T_k(x)$, $T_2'(x) = 4x = 4T_1(x) = 4 \sum^\star T_k$ et $T_2''(x) = 4 = 8 \sum^\star T_k$, ce qui initialise la récurrence.

On suppose à présent $n>2$ et que le résultat est vrai pour tout $k<n$. On a alors 
\begin{align*}
 2 T_{n-1}(x) &= \frac{1}{n} T_n'(x) - \frac{1}{n-2}T_{n-2}(x), \quad \textnormal{alors} \\
  \frac{1}{n} T_n'(x) &= 2T_{n-1}(x) + \frac{1}{n-2}T_{n-2}(x), \quad \textnormal{ce qui donne} \\ 
 T_n'(x) &= 2nT_{n-1}(x) + \frac{n}{n-2}T_{n-2}'(x) \\
 &= 2n T_{n-1}(x) + \frac{n}{n-2}\ 2(n-2) \sum_{k=0}^{n-3} \phantom{}^\star T_k \\
 &= 2n \sum_{k=0}^{n-1} \phantom{}^\star T_k(x).
\end{align*}

A noter que l'on a inclus la condition de parité dans la définition du symbole $\sum^\star$. On a donc montré la première relation. Pour la seconde on a 

Pour la seconde relation on a 
\begin{align*}
 T_n''(x) &= 2n T_{n-1}'(x) + \frac{n}{n-2} T_{n-2}''(x) \\
 &= 4n(n-1) \sum_{k=0}^{n-2} \phantom{}^\star T_k(x) + n \sum_{k=0}^{n-4} \phantom{}^\star ((n-4)^2 - k^2) T_k(x) \\
 &= n \left [ 4(n-1) \sum_{k=0}^{n-2} \phantom{}^\star T_k(x) + \sum_{k=0}^{n-4} \phantom{}^\star ((n-2)^2 - k^2) T_k(x) \right ] \\
 &= n \left [ (4n-4) T_{n-2}(x) + \sum_{k=0}^{n-4} \phantom{}^\star (4(n-1) + (n-2)^2 - k^2) T_k(x) \right ] \\
 &= n \left [ (n^2 - (n-2)^2) T_{n-2}(x) + \sum_{k=0}^{n-4} \phantom{}^\star (n^2 - k^2) T_k(x) \right ] \\
 &= n \sum_{k=0}^{n-2} \phantom{}^\star (n^2 - k^2)T_k(x).
\end{align*}
Ce qu'il fallait montrer.

\subsection{Question 3}

\paragraph{a.} Pour tout $n$ on a $T_n(\cos(x)) = \cos(nx)$. Alors en posant $\theta_k = \frac{2k + 1}{2n}\pi$ pour $k \in \{0, \dots, n-1\}$ on a $\cos(n \theta_k) = \cos \left ( \frac{(2k+1)\pi}{2}\right) = 0$ et donc $T_n(\cos(\theta_k)) = 0$. Alors la famille $\{\cos(\theta_k)\}_{k \in \{0, \dots, n-1\}}$ donne $n$ racines distinctes de $\widetilde{T_n} = 2^{-(n-1)} T_n$ qui est unitaire. Par le théorème fondamentale de l'algèbre on sait qu'il ne peut pas exister d'autre racine du polynôme $\widetilde{T_n}$ et on a de plus la factorisation
\[
 T_n(x) = 2^{n-1}\prod_{k=0}^{n-1}(x - \cos(\theta_k)).
\]

\paragraph{b.} A partir de la relation $T_{n+2}(x) = 2xT_{n+1}(x) - T_n(x)$ on trouve facilement que $T_n(1) = 1$ et $T_n(-1) = (-1)^n$. De plus on avait déjà que le coefficient dominant était $2^{n-1}$.

\subsection{Question 4}

On a 
\begin{align*}
 \scalaire{T_n}{T_m}_\omega &= \int_{-1}^1 \frac{T_n(x) T_m(x)}{\sqrt{1 - x^2}}\ dx  = \int_{0}^{\pi} T_n(\cos(\xi)) T_m(\cos(\xi))\ d\xi \\
 &= \int_{0}^{\pi} \cos(n\xi)\cos(m\xi)\ d\xi = \begin{cases}
                                                 \pi \quad \textnormal{si } n=m = 0 \\
                                                 \frac{\pi}{2} \quad \textnormal{si } n=m \neq 0 \\
                                                 0 \quad \textnormal{ sinon}
                                                \end{cases}.
\end{align*}
Ce qui montre que la famille est orthogonale pour le produit scalaire $\scalaire{\cdot}{\cdot}_\omega$. De plus la famille est constituée de $n+1$ polynômes indépendants (car de degrés différents) dans un espace de dimension $n+1$. Il s'agit donc bien d'une base orthogonale.


\section{Système linéaire issu de la méthode des résidus pondérés}

On considère le problème : trouver une fonction $u$ telle que 
\begin{align*}
 - \alpha u''(x) + \gamma u(x) &= f(x) \quad \forall x \in ]-1,1[, \\
 u(-1) = u(1) &= 0.
\end{align*}

Pour tout $k \in \N$ on désigne pas $\phi_k$ la fonction définie sur $]-1,1[$ par 
\begin{align*}
 \phi_k(x) = \begin{cases}
              T_{k+2}(x) - T_0(x) \quad \textnormal{si $k$ est pair},\\
              T_{k+2}(x) - T_1(x) \quad \textnormal{si $k$ est impair}
             \end{cases}.
\end{align*}



\subsection{Question 1}

On montre que la famille $\Phi = \{ \phi_0, \dots, \phi_{N-2}\}$ est une base de l'espace vectoriel 
\[
 V_N = \{v \in \R_N[X] : v(-1) = v(1) = 0 \}.
\]

$V_N$ est un sous-espace de l'espace vectoriel des polynômes de degrés compris entre $2$ et $N$, en effet un polynôme de $V_N$ dont admettre au moins deux racines. Cet espace est donc de dimension au plus $N-1$. Or la famille $\Phi$ contient $N-1$ polynômes linéairement indépendants de $V_N$, car ils sont tous de degrés différents et que $\phi_k(1) = \phi_k(-1) = 0$ d'après la question 2.3.b, elle est donc libre maximale dans $V_N$, c'est donc une base de $V_N$.

\subsection{Question 2}

On a l'opérateur différentiel $ \mathcal{L}u = -\alpha u'' + \gamma u$. On cherche $\widehat{u_N} \in V_N$ tel que pour tout $v_N \in V_N$ on ait
\[
 \scalaireo{\mathcal{L}[\widehat{u_N}]}{v_N} = \scalaireo{f}{v_N}.
\]

Ce qui revient à 
\[
 \int_{-1}^{1} \frac{(- (\alpha \widehat{u_N}')' + \gamma \widehat{u_N})v_N}{\sqrt{1 - x^2}}\ dx = \int_{-1}^1 \frac{f v_N}{\sqrt{1 - x^2}},
\]
or comme la fonction $x \mapsto \frac{1}{\sqrt{1 - x^2}}$ est une fonction strictement positive sur $]-1,1[$, cela revient à 
\[
 \int_{-1}^1 - (\alpha \widehat{u_N}')'v_N\ dx + \int_{-1}^1 \gamma \widehat{u_N}v_N \ dx = \int_{-1}^1 f v_N \ dx
\]
et en intégrant par partie on trouve 
\[
 \int_{-1}^1 \alpha \widehat{u_N}'v_N\ dx + \int_{-1}^1 \gamma \widehat{u_N}v_N \ dx = \int_{-1}^1 f v_N \ dx
\]
car $v_N(-1) = v_N(1) = 0$. On retrouve bien une formulation variationnelle exprimée dans un espace vectoriel de dimension finie. D'où le parallèle avec la méthode de Galerkine.

\subsection{Question 3}
On commence par utiliser la question 2.4 pour déterminer la valeur de $\scalaireo{\phi_l}{\phi_k}$. 
\begin{itemize}
 \item Si $k = l$ est pair, on a 
 \[
  \scalaireo{\phi_k}{\phi_k} = \scalaireo{T_{k+2}}{T_{k+2}} + \scalaireo{T_0}{T_0} = \frac{\pi}{2} + \pi  = \frac{3\pi}{2}.
 \]
 
 \item Si $k=l$ est impaire :
 \[
  \scalaireo{\phi_k}{\phi_k} = \scalaireo{T_{k+2}}{T_{k+2}} + \scalaireo{T_1}{T_1} = \frac{\pi}{2} + \frac{\pi}{2}  = \pi.
 \]
 
 \item Si $k \neq l$ tous deux pairs :
 \[
  \scalaireo{\phi_l}{\phi_k} = \scalaireo{T_0}{T_0} = \pi.
 \]
 
 \item Si $k \neq l$ tous deux impairs :
 \[
  \scalaireo{\phi_l}{\phi_k} = \scalaireo{T_0}{T_0} = \frac{\pi}{2}.
 \]

 \item Enfin si $k$ et $l$ sont de parité opposée on a clairement 
 \[
  \scalaireo{\phi_k}{\phi_l} = 0.
 \]
 \end{itemize}
 On a bien trouvé les valeurs recherchées.
 
 On a de plus $\phi_k'' = T_{k+2}'' = (k+2) \sum_{i=0}^{k \star} ((k+2)^2 - i^2)T_i$. Ce qui nous permet de déterminer la valeur de $\scalaireo{\phi_l''}{\phi_k}$.
 \begin{itemize}
  \item Si $k$ et $l$ sont pairs et $0 \leq k \leq l-2$ on a 
  \begin{align*}
   \scalaireo{\phi_l''}{\phi_k} &= \scalaireo{T_{l+2}''}{T_{k+2} - T_0} = (l+2) \sum_{i=0}^{l} \phantom{}^\star ((l+2)^2 - i^2) \left ( \scalaireo{T_i}{T_{k+2}} - \scalaireo{T_i}{T_0} \right ) \\
   &= (l+2) \left ( (l+2)^2 - (k+2)^2 \right ) \scalaireo{T_{k+2}}{T_{k+2}} - (l+2)^2 \scalaireo{\frac{T_0}{2}}{T_0} \\
   &= (l+2) \left ( (l+2)^2 - (k+2)^2 \right ) \frac{\pi}{2} - (l+2)^2 \frac{\pi}{2} \\
   &= -(l+2)(k+2)^2 \frac{\pi}{2}.
  \end{align*}
  
  \item Si $k$ et $l$ sont pairs et $ 0 \leq l-2 < k$ :
  \begin{align*}
   \scalaireo{\phi_l''}{\phi_k} &= \scalaireo{T_{l+2}''}{T_{k+2} - T_0} = (l+2) \sum_{i=0}^{l} \phantom{}^\star ((l+2)^2 - i^2) \left ( \scalaireo{T_i}{T_{k+2}} - \scalaireo{T_i}{T_0} \right ) \\
   &= -(l+2) (l+2)^2 \scalaireo{\frac{T_0}{2}}{T_0} \\
   &= - (l+2)^3 \frac{\pi}{2}.
  \end{align*}

  \item Si $k$ et $l$ sont impairs et $0 \leq k \leq l-2$ :
  \begin{align*}
   \scalaireo{\phi_l''}{\phi_k} &= \scalaireo{T_{l+2}''}{T_{k+2} - T_1} = (l+2) \sum_{i=0}^{l} \phantom{}^\star ((l+2)^2 - i^2) \left ( \scalaireo{T_i}{T_{k+2}} - \scalaireo{T_i}{T_1} \right ) \\
   &= (l+2) \left ( (l+2)^2 - (k+2)^2 \right ) \scalaireo{T_{k+2}}{T_{k+2}} - ((l+2)^2 - 1) \scalaireo{T_1}{T_1} \\
   &= (l+2) \left ( (l+2)^2 - (k+2)^2 \right ) \frac{\pi}{2} - ((l+2)^2 - 1) \frac{\pi}{2} \\
   &= -(l+2)((k+2)^2 + 1) \frac{\pi}{2}.
  \end{align*}

  \item  Si $k$ et $l$ sont impairs et $ 0 \leq l-2 < k$ :
  \begin{align*}
   \scalaireo{\phi_l''}{\phi_k} &= \scalaireo{T_{l+2}''}{T_{k+2} - T_1} = (l+2) \sum_{i=0}^{l} \phantom{}^\star ((l+2)^2 - i^2) \left ( \scalaireo{T_i}{T_{k+2}} - \scalaireo{T_i}{T_1} \right ) \\
   &= -(l+2) ((l+2)^2 - 1) \scalaireo{T_1}{T_1} \\
   &= -(l+2) ((l+2)^2 - 1) \frac{\pi}{2}.
  \end{align*}

  \item Enfin il est facile de voir que si $k$ $l$ sont de parité opposée on a $\scalaireo{\phi_l''}{\phi_k} = 0$.
 \end{itemize}
 
 \subsection{Question 4}
 On considère une fonction $f \in L^2([-1,1])$, on s'intéresse à $\scalaireo{f}{T_n}$.
 
 \paragraph{a.} On a 
 \begin{align*}
  \scalaireo{f}{T_n} &= \int_{-1}^1 \frac{f(x)T_n(x)}{\sqrt{1 - x^2}}\ dx = \int_0^\pi \frac{f(\cos(t))T_n(\cos(t))}{\sqrt{1 - \cos^2(t)}} \sin(t)\ dt \\ 
  &= \int_0^\pi f(\cos(t))\cos(nt)\ dt = \frac{1}{2} \int_0^{2\pi} f(\cos(t))\cos(nt)\ dt.
 \end{align*}
 Où l'on a commencé par faire le changement de variable $x = \cos(t)$ puis on a utilisé la parité de la fonction $t \mapsto \cos(t)$.
 
 \paragraph{b.} La méthode des rectangles donne 
 \begin{align*}
  I_n &= \frac{2\pi}{2(N+1)} \sum_{j=0}^N f\left(\cos\left(\frac{2j\pi}{N+1}\right) \right) \cos \left (\frac{n 2 \pi j}{N+1} \right ) \\
  &= \frac{\pi}{N+1} \sum_{j=0}^N f \left ( \cos \left (\frac{2j\pi}{N+1} \right) \right ) \Re \left [e^{-i \frac{2n\pi j}{N+1}} \right ]\\
  &= \frac{\pi}{N+1} \sum_{j=0}^N w_j \Re \left[e^{-2i\pi \frac{nj}{N+1}} \right ] \\
  &= \frac{\pi}{N+1} \Re \left [ \sum_{j=0}^N w_j e^{-2i\pi \frac{nj}{N+1}} \right ].
 \end{align*}

 \paragraph{c.} Dans le cas pair on a 
 \begin{align*}
  \scalaireo{f}{\phi_n} &= \scalaireo{f}{T_{n+2}} - \scalaireo{f}{T_0} \\
  &= \frac{\pi}{N+1} \Re \left [ \sum_{j=0}^N w_j \left ( e^{-2i\pi \frac{(n+2)j}{N+1}} - 1 \right) \right ].
 \end{align*}
 
 Dans le cas impaire on a 
\begin{align*}
 \scalaireo{f}{\phi_n} &= \scalaireo{f}{T_{n+2}} - \scalaireo{f}{T_1} \\
  &= \frac{\pi}{N+1} \Re \left [ \sum_{j=0}^N w_j  e^{-2i\pi \frac{j}{N+1}}\left ( e^{n+2} -1 \right ) \right ].
\end{align*}


\section{Transform\'ee de Fourier rapide}

\subsection{Question 2.a}

Soit p et n deux entiers naturels tels que $p > 0$. On calcule les valeurs exactes des int\'egrales de la mani\`ere suivante : (on suppose premi\`erement n strictement positif)

\begin{align*}
 \langle f,T_n \rangle _\omega &= \frac{1}{2} \int_0^{2\pi} f(\cos(t))\cos(nt)\ dt
 = \frac{1}{2} \int_0^{2\pi} t^p (2\pi - t)^p\cos(nt)\ dt\\
 &= \frac{1}{2} \int_0^{2\pi} \left[t (2\pi - t)\right]^p\cos(nt)\ dt
\end{align*}

On effetue une IPP avec $u=\left[t (2\pi - t)\right]^p$ et $v'=\cos(nt)$.\\
On a donc $u'=2p(pi-t)\left[t (2\pi - t)\right]^(p-1)$ et $v=\frac{1}{n} \sin(nt)$. Ainsi :

\begin{align*}
 \langle f,T_n \rangle _\omega &= \frac{1}{2} \left[ \left[t (2\pi - t)\right]^p \frac{1}{n} \sin(nt) \right]_0 ^{2\pi} + \frac{1}{2} \int_0^{2\pi}  \frac{1}{n} 2p(pi-t)\left[t (2\pi - t)\right]^{p-1} \sin(nt) \ dt \\
 &= \frac{p}{n} \int_0^{2\pi} (pi-t)\left[t (2\pi - t)\right]^{p-1} \sin(nt) \ dt
\end{align*}

Dans le cas ou p=1, on a alors :

\begin{align*}
 \langle f,T_0 \rangle _\omega &=  \frac{1}{n} \int_0^{2\pi} (pi-t) \sin(nt) \ dt\\
 &=\frac{1}{n^2} \left[(\pi -t)  \cos(nt) \right]_0 ^{2\pi} + \frac{1}{n^2} \int_0^{2\pi} \cos(nt) \ dt\\
 &= - \frac{\pi}{n^2} + \frac{1}{n^3} \int_0^{2\pi n} \cos(\phi) \ d\phi\\
 &= - \frac{\pi}{n^2}
\end{align*}

Lorsque n=0, on a a :
\begin{align*}
 \langle f,T_n \rangle _\omega &=  \frac{1}{2} \int_0^{2\pi} f(\cos(t))\ dt
 =\frac{1}{2} \int_0^{2\pi} t^p (2\pi - t)^p \ dt 
 =\frac{1}{2} \int_0^{2\pi} \left( 2 \pi t - t^2 \right)^p \ dt\\
 &= \frac{1}{2} \int_0^{2\pi} \left( 2 \pi t - t^2 \right) \ dt
 = \left[\pi t^2 - \frac{t^3}{3}  \right]_0 ^{2\pi}
 = \frac{2 \pi^3}{3}
\end{align*}

Dans le cas ou p=4, on a :
\begin{align*}
 \langle f,T_n \rangle _\omega &= \frac{p}{n} \int_0^{2\pi} (pi-t)\left[t (2\pi - t)\right]^{3} \sin(nt) \ dt
\end{align*}

Lorsque n=0, on a a :
\begin{align*}
 \langle f,T_0 \rangle _\omega &=  \frac{1}{2} \int_0^{2\pi} f(\cos(t))\ dt
 =\frac{1}{2} \int_0^{2\pi} t^4 (2\pi - t)^4 \ dt 
 =\frac{1}{2} \int_0^{2\pi} \left( 2 \pi t - t^2 \right)^4 \ dt\\
\end{align*}

\subsection{Question 2.c}




\section{Méthode de Gauss}

\subsection{Question 1}

Pour chaque ligne $j > 1$, et en partant la dernière ligne $j = n$, l'idée est de soustraire la ligne $j-1$ à la ligne $j$. La structure particulière de la matrice nous permet de ne pas réaliser la totalité des calculs. Pour chaque ligne $j$ on peut directement fixer les $j-2$ premiers coefficients à $0$ et il ne reste plus qu'à réaliser $n - j +2$ soustractions. Cette méthode donne une matrice de la forme souhaitée en réalisant $\sum_{k=1}^n (n - k + 2) = \sum_{k=0}^{n-1} (k + 2) \sim n^2/2$ soustractions.

\subsection{Question 2}

Pour chaque colonne $c_k$ pour $k>1$ et en partant de la colonne la plus à droite $k = n$, on élimine le coefficient $\hat {b}_{k-1}$ en calculant
\[
 c_{k-1} = c_{k-1} - \frac{\hat {b}_{k-1}}{\hat{a}_{k,k}} c_k.
\]
Ce qui donne lieu à $3n(n-1)$ opérations. On obtient alors un matrice triangulaire supérieure qui nous permet de résoudre le système linéaire en $n^2$ opérations comme dans le cas de la méthode de Gauss classique. Au final on a donc bien résolu le système linéaire avec un algorithme demandant de l'ordre de $n^2$ opérations.

\begin{remarque}
 Il faut remarquer que nous avons fait l'hypothèse que le coefficients diagonaux restaient non-nuls tout au long de la procédure.
\end{remarque}

\section{Mise en œuvre numérique}

\paragraph{1)} On sait déjà que l'on a le système linéaire $AU = F$ où $A = (a_{i,j})_{0 \leq i,j \leq N-2}$ et $a_{i,j} = 0$ dès que $i$ et $j$ sont de parité oppposée. De plus en notant $F = (f_i)_{0 \leq i \leq N-2}$ on a avec les conventions de l'énoncé
\[
 f_i = \sum_{k = 0}^K (\alpha \scalaire{\phi_{2k}''}{\phi_i} - \gamma \scalaire{\phi_{2k}}{\phi_i})u_{2k}
\]
lorsque $i$ est pair et 
\[
 f_i = \sum_{k=0}^K (\alpha \scalaire{\phi_{2k+1}''}{\phi_i} - \gamma \scalaire{\phi_{2k+1}}{\phi_i})u_{2k+1}
\]
lorsque $i$ est impair. Alors en notant $G = \begin{pmatrix} G^1 \\ G^2                         \end{pmatrix}$ avec $G^1 = \begin{pmatrix}f_0 \\ f_2 \\ \vdots \\ f_{2K} \end{pmatrix}$ et $G^2 = \begin{pmatrix}f_1 \\ f_3 \\ \vdots \\ f_{2K+1} \end{pmatrix}$. On trouve bien un système équivalent $MV = G$ où $M$ est de la forme souhaitée.


\end{document}
