\documentclass[a4paper,12pt,french]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{amssymb}
\usepackage{mathrsfs} 
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{caption}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage[document]{ragged2e}
\usepackage{hyperref}
\usepackage{etoolbox}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{epstopdf}
\usepackage[nottoc, notlof, notlot]{tocbibind}
\usepackage{fourier}

%opening
\title{DM RNDP}
\date{}
\author{Jules Berry, Thomas Poisson}

\theoremstyle{definition}
\newtheorem{definition}{D\'efinition}[section]
\AtEndEnvironment{definition}{\hfill $\square$}
\newtheorem{remarque}{Remarque}[section]

\theoremstyle{theorem}
\newtheorem{prop}{Proposition}[section]
\newtheorem{thm}{Th\'eor\`eme}[section]
\newtheorem{lemme}{Lemme}[section]
\newtheorem{corollaire}{Corollaire}[section]


\renewcommand\qedsymbol{$\blacksquare$}
\newcommand{\T}{\mathbb{T}}
\newcommand{\norm}[2]{\lVert{#1}\rVert_{#2}}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\Lp}[1]{L^{#1}(\T)}
\newcommand{\C}{\mathcal{C}}
\newcommand{\module}[1]{\left \lvert #1 \right \rvert}
\newcommand{\scalaire}[2]{\left \langle {#1},\ {#2} \right \rangle}




\begin{document}

\maketitle

\justify

\tableofcontents

\newpage

\section{Préliminaires}
\subsection{Question 1}
 \item On cherche une fonction $u \in \C^2([-1,1])$ telle que 
 \begin{equation}\label{eq:problème_1}
  \begin{cases}
   -(\alpha(x) u'(x))' + \gamma(x)u(x) = f(x) \quad \forall x \in ] -1, 1[, \\
   u(-1) = c_1,\ u(1) = c_2
  \end{cases}.
 \end{equation}

 Soit $u$ un solution de ce problème et on pose 
 \[
  v(x) = u(x) - c_1 \frac{x - 1}{2} - c_2 \frac{x+1}{2}
 \]
cette fonction est alors aussi $\C^2([-1,1])$ et on a de plus 
\[
 v'(x) = u'(x) - \frac{c_1 + c_2}{2}, \quad v''(x) = u''(x).
\]
En injectant cette fonction dans l'EDO de \eqref{eq:problème_1} on a
\begin{align*}
 -(\alpha(x)v'(x))' + \gamma(x)v(x) &= -\alpha'(x)v'(x) - \alpha(x)v''(x) + \gamma(x)v(x) \\
 &= -(\alpha(x)u'(x))' + \frac{c_1 + c_2}{2}\alpha'(x) + \gamma(x)u(x) - \gamma(x)\left (c_1 \frac{x-1}{2} + c_2 \frac{x+1}{2} \right)
\end{align*}
On a donc que la fonction $v$ est solution du problème
\begin{equation}\label{eq:problème_2}
 \begin{cases}
  -(\alpha(x)v'(x))' + \gamma(x)v(x) = \tilde f(x) \\
  v(-1) = v(1) = 0
 \end{cases}
\end{equation}
où $\tilde f(x) = f(x) + \gamma(x)\left(c_1 \frac{x-1}{2} + c_2 \frac{x+1}{2}\right) - \frac{c_1 + c_2}{2}\alpha'(x)$.

De plus il est clair que $v(-1) = v(1) = 0$ et comme $f \in L^2(]-1,1[)$ , $\alpha \in \C^1([-1,1])$ et $\gamma \in L^\infty ([-1,1]) \subset L^2(]-1,1[)$ on a aussi $\tilde f \in L^2([-1,1])$. 

On voit alors que le problème \eqref{eq:problème_2} est de la forme souhaitée. De plus si $v$ est une solution de ce problème et en posant $w(x) = v(x) + c_1 \frac{x - 1}{2} + c_2 \frac{x+1}{2}$, on peut voir que $w$ est une solution de \eqref{eq:problème_1}. On a donc montré que l'étude de ce dernier se ramène à l'étude de \eqref{eq:problème_2}.

\subsection{Question 2}

On pose $u = \rho v$ où $\rho : x \in [-1,1] \mapsto \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right)$.
Alors si $u$ est une solution de l'EDO 
\begin{equation}
 -(\alpha u')' + \beta u' + \gamma u = f
\end{equation}
On remarque alors que 
\begin{align*}
 \rho'(x) &= \frac{d}{dx} \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right) = \frac{\beta(x)}{2\alpha(x)} \exp \left ( \frac{1}{2} \int_{-1}^x \frac{\beta(t)}{\alpha(t)}\ dt \right) \\
 &= \frac{\beta(x)}{2\alpha(x)} \rho(x).
\end{align*}
Et par suite 
\[
 \rho'' = \frac{1}{2} \left ( \frac{\beta' \alpha - \beta \alpha'}{\alpha^2}\rho + \frac{\beta}{\alpha} \rho'\right) = \frac{\beta' \alpha + 2 \beta^2 - \beta \alpha'}{2 \alpha^2}\rho.
\]

En réétudiant l'EDO on trouve donc 
\begin{align*}
 -(\alpha u')' + \beta u' + \gamma u &= - \alpha' (\rho' v + \rho v') - \alpha ( \rho '' v + 2 \rho' v' + \rho v'') + \beta (\rho' v + \rho v') + \gamma \rho v \\
 &= \rho \left ( -\frac{\alpha' \beta v}{\alpha} - \alpha' v' - \frac{\beta' v}{2} - \frac{\beta^2 v}{\alpha} + \frac{\beta \alpha' v }{\alpha} - \beta v' - \alpha v'' + \frac{\beta^2 v}{\alpha} + \beta v' + \gamma v \right) = f
\end{align*}
Par définition de la fonction de $\rho$ celle-ci est strictement positive et on peut donc diviser par $\rho$ dans l'équation. Alors en simplifiant le membre de gauche on trouve
\[
 - \alpha' v' - \alpha v'' - \frac{1}{2} \beta' v +\gamma v = \frac{f}{\rho}.
\]
Alors en posant $\delta = \gamma - \frac{1}{2}\beta'$ et $g = \frac{f}{\rho}$. On trouve donc 
\begin{equation}\label{eq:EDO_1}
 -(\alpha v')' + \delta v = g.
\end{equation}
On remarque au passage que nous avons supposé que la fonction $\beta$ était au moins $\C^1$.

\subsection{Question 3}

On considère l'EDO $-(\alpha u')' + \gamma u = f$ sur $[a,b]$. En posant 
\[
 h : x \in [-1,1] \mapsto a \frac{x-1}{2} + b \frac{x+1}{2}
\]
et on considérant la fonction $v : x \in [-1,1] \mapsto u \circ h(x)$ on trouve que $v(-1) = u(a)$ et $v(1) = u(b)$. De plus en posant aussi $\tilde \alpha = \alpha \circ h$, $\tilde \gamma = \frac{b - a}{2} \gamma \circ h$ on a en supposant que $u$ est une solution de l'EDO
\begin{align*}
 -(\tilde \alpha(x) v'(x))' + \tilde \gamma(x) v(x) &= -(\alpha(h(x))(u(h(x)))')' + \frac{a + b}{2} \gamma(h(x))v(h(x)) \\
 &= -\frac{a + b}{2}( \alpha (h(x)) u'(h(x)))' + \frac{a + b}{2} \gamma(h(x)) u(h(x)) \\
 &= \frac{a+b}{2} f(h(x)).
\end{align*}
On peut alors poser $\tilde f(x) = \frac{a+b}{2} f \circ h (x)$ et on a alors que $v$ est solution de la nouvelle EDO 
\[
 -(\tilde \alpha(x) v'(x))' + \tilde \gamma (x) u(x) = \tilde f(x).
\]
Comme la fonction $h$ est un polynôme de degrés un elle est bijective de $[-1,1]$ dans $[a,b]$. Alors si $v$ est solution de la dernière EDO on peut inverser la construction en posant $u =h^{-1} \circ v$ on voit que $u$ est solution de la première EDO.

\subsection{Quastion 4}

On cherche ici une solution $u \in H^2(]-1,1[)$ de 

\begin{equation}\label{eq:problem_3}
 \begin{cases}
  -(\alpha(x) u'(x))' + \gamma(x) u(x) = f(x) \quad \forall x \in ]-1,1[ \\
  u(-1) = u(1) = 0
 \end{cases}.
\end{equation}


On commence par trouver une solution à la formulation variationnelle de \eqref{eq:problem_3} dans l'espace $H_0^1(]-1,1[)$. Soit $\phi \in H_0^1(]-1,1[)$ on a alors 
\[
 -\int _{-1}^1 (\alpha(t)u'(t))' \phi(t)\ dt + \int _{-1}^1 \gamma(t) u(t) \phi(t) \ dt = \int _{-1}^1 f(t) \phi(t) \ dt.
\]
En intégrant par parties on trouve
\[
 \int _{-1}^1 (\alpha(t)u'(t)) \phi'(t)\ dt + \int _{-1}^1 \gamma(t) u(t) \phi(t) \ dt = \int _{-1}^1 f(t) \phi(t) \ dt.
\]

On cherche ensuite à appliquer le théorème de Lax-Milgram dans $H_0^1(]-1,1[)$. Pour cela on pose $a$ la forme bilinéaire 
\[
 a : (\phi,\psi) \in (H_0^1(]-1,1[))^2 \mapsto \int _{-1}^1 (\alpha(t)\phi'(t)) \psi'(t)\ dt + \int _{-1}^1 \gamma(t) \phi(t) \psi(t) \ dt
\]
et $l$ la forme linéaire 
\[
 l : \phi \in H_0^1(]-1,1[) \mapsto \int _{-1}^1 f(t) \phi(t) \ dt.
\]

On a alors 
\[
 \module{\langle l, \phi \rangle} \leq  \int _{-1}^1 \module{f(t) \phi(t)} \ dt \leq \norm{f}{L^2}\norm{\phi}{L^2} \leq \norm{f}{L^2}\norm{\phi}{H^1}
\]
ce qui montre que $l$ est une forme linéaire continue sur $H_0^1(]-1,1[)$.
De plus on a aussi 
\begin{align*}
 \module{a(\phi,\psi)} &\leq \int _{-1}^1 \module{\alpha(t)\phi'(t) \psi'(t)} \ dt + \int _{-1}^1 \module{\gamma(t) \phi(t) \psi(t)} \ dt \\
 & \leq \norm{\alpha}{L^\infty} \int _{-1}^1 \module{\phi'(t) \psi'(t)} \ dt + \norm{\gamma}{L^\infty}\int _{-1}^1 \module{\phi(t) \psi(t)} \ dt \\
 & \leq M \left ( \norm{\phi'}{L^2} \norm{\psi'}{L^2} + \norm{\phi}{L^2} \norm{\psi}{L^2} \right ) \\
 & \leq M \sqrt{\norm{\phi}{L^2}^2 + \norm{\phi'}{L^2}^2} \sqrt {\norm{\psi}{L^2}^2 + \norm{\psi'}{L^2}^2} \\
 & = M \norm{\phi}{H^1}\norm{\psi}{H^1}
\end{align*}
Ce qui montre que $a$ est une forme bilinéaire continue sur $H_0^1(]-1,1[)$.

Il reste donc a montrer que $a$ est coercive. Pour cela il suffit de voir que 
\[
 a(\phi,\phi) = \int_{-1}^1 \alpha(t) \module{\phi'(t)}^2\ dt + \int_{-1}^1 \gamma(t) \module{\phi(t)}^2\ dt \geq \alpha_0 \norm{\phi'}{L^2}^2
\]
et par l'inégalité de Poincaré on sait que la norme $\phi \mapsto \norm{\phi'}{L^2}$ est équivalente à la norme usuelle de $H_0^1(]-1,1[)$. 

On peut à présent appliquer le théorème de Lax-Milgram pour obtenir l'existence d'une unique solution $u$ à la formulation variationnelle du problème \eqref{eq:problem_3} dans $H_0^1(]-1,1[)$. Il nous faut à présent montrer que cette solution est dans $H_0^2(]-1,1[)$, c'est-à-dire qu'elle admet une dérivée faible seconde qui soit dans $L^2(]-1,1[)$. On cherche donc une fonction $g \in L^2(]-1,1[)$ qui vérifie 
\[
 - \int u \phi' = \int g \phi
\]
pour toute fonction test $\phi \in \mathcal{D}(]-1,1[)$. 

Comme $u$ est solution de la formulation variationnelle du problème, on sait déjà que 
\[
 \int _{-1}^1 (\alpha(t)u'(t)) \phi'(t)\ dt = \int _{-1}^1 (f(t) - \gamma(t) u(t)) \phi(t) \ dt.
\]
Ce qui signifie que la fonction $\alpha u'$ admet comme dérivée faible $\gamma u -f$ qui se trouve être dans $L^2$. On a donc que $\alpha u \in H^1$. Or on sait que $(\alpha u')' = \alpha' u' + \alpha u''$. Ce qui donne 
\[
 u'' = \frac{\gamma u - \alpha' u' - f}{\alpha}
\]
qui a bien un sens car $\alpha$ est supposée strictement positive.De plus peut voir que $u''$ est dans $L^2$. Ce qui montre que la solution $u$ de \eqref{eq:problem_3} est dans $H^2$.

\subsection{Question 5}

On se donne la fonction 
\[
 \omega (x) = \frac{1}{\sqrt{1 - x^2}}
\]
et on cherche à montrer que la forme bilinéaire 
\[
 \scalaire{\phi}{\psi}_\omega = \int_{-1}^1 \phi(x) \psi(x) \omega(x) \ dx 
\]
définit un produit scalaire sur $\mathcal{C}^0([-1,1])$.

La forme bilinéaire $\scalaire{\cdot}{\cdot}\omega$ est clairement symétrique et on a 
\begin{align*}
 \scalaire{\phi}{\phi}_\omega = \int \frac{\module{\phi(x)}^2}{\sqrt{1-x^2}} \ dx \geq 0
\end{align*}
et on remarque que $\scalaire{\phi}{\phi}_\omega = 0$ si, et seulement si, $\phi = 0$ car $\omega$ est strictement positive sur $]-1,1[$.
Il reste juste à monter que l'intégrale est bien définie. Or on a 
\begin{align*}
 \module{\scalaire{\phi}{\psi}_\omega} \leq \norm{\phi}{\infty} \norm{\psi}{\infty} \int_{-1}^1 \frac{1}{\sqrt{1 - x^2}}\ dx.
\end{align*}

Or on a 
\begin{align*}
 \int_{-1}^1 \frac{1}{\sqrt{1 - x^2}}\ dx &= 2 \int_0^1 \frac{1}{\sqrt{1-x} \sqrt{1+x}}\ dx \\
 & \leq 2 \int_0^1 \frac{1}{\sqrt{1-x}}\ dx < + \infty.
\end{align*}
Ce qui montre que $\scalaire{\cdot}{\cdot}\omega$ définit un produit scalaire.





\newpage
\section{Méthode des rectangles pour l’approximation de l’intégrale d’une fonction périodique sur un intervalle de période}

On rappelle ici le r\'esultat suivant (utilis\'e \`a plusieurs reprises par la suite) :
En consid\'erant une fonction f de $\mathbb{R}$ dans $\mathbb{R}$, p\'eriodique de p\'eriode $2 \pi$ assez r\'eguli\`ere. Alors la s\'erie de fourier associ\'ee \`a f, not\'ee $S_Nf$ converge normalement (et donc uniform\'ement) vers f sur $[0, 2\pi]$ lorsque N tend vers l'infini

\subsection{Question 1}

Soient n et k deux entiers naturels tels que $n \geq 2$ et $k \geq 2$.\\.
On pose $k=pn+r$, avec $0 < r \leq n-1$, la division euclidienne de k par n. Montrons que $S_{n,k} = 0$ si $r=0$ et  $S_{n,k} = n$ sinon :
\[
S_{n,k} = \sum_{j=0}^{n-1} cos\left(\frac{2kj\pi}{n}\right)
= \sum_{j=0}^{n-1} cos\left(\frac{2pnj\pi}{n}+\frac{2rj\pi}{n}\right)
= \sum_{j=0}^{n-1} cos\left(2pj\pi+\frac{2rj\pi}{n} \right)
\]
la fonction cosinus \'etant p\'eriodique de p\'eriode $2\pi$, on a donc :
\[
S_{n,k} = \sum_{j=0}^{n-1} cos\left(\frac{2rj\pi}{n} \right)
\]
Si r=0, on a directement le r\'esultat :
\[
S_{n,k} = \sum_{j=0}^{n-1} cos\left(\frac{2\pi}{n} \right)
= \sum_{j=0}^{n-1} 1
= n
\]
Sinon, on utilise la formule d'Euler pour le cosinus :
\[
\cos(x)= Re\left( {\mathrm  {e}}^{{{\mathrm  {i}}\,x}} \right) 
\]
O\`u Re d\'esigne la partie r\'elle d'un complexe.
Ce qui nous donne :
\[
S_{n,k} = \sum_{j=0}^{n-1} Re\left( {\mathrm  {e}}^{{{\mathrm  {i}}\,\frac{2rj\pi}{n}}} \right)
=Re\left( \sum_{j=0}^{n-1} {\mathrm  {e}}^{{{\mathrm  {i}}\,\frac{2rj\pi}{n}}} \right)
\]
OR, les $\mathrm{e}^{{{\mathrm  {i}}\,\frac{2rj\pi}{n}}}$ sont les n-i\`emes racines de l'unit\'e. On a donc la propri\'et\'e que leur somme vaut 0. Ceci nous permet de conclure :
\[
S_{n,k} =Re\left( \sum_{j=0}^{n-1} {\mathrm  {e}}^{{{\mathrm  {i}}\,\frac{2rj\pi}{n}}} \right)
=Re\left( 0 \right)
=0
\]

\subsection{Question 2}
\subsubsection {Partie a}

Soit $\left(x_j\right)_{0 \leq j \leq n} $ une subdivision uniforme de l'intervalle $[0, \pi]$. Notons h le pas de la subdivision.\\
On a par d\'efinition de la formule de quadrature des rectangles \`a gauche et d'apr\`es le d\'evelopppement en s\'erie de f :
\[
I_n = \sum_{j=0}^{n-1} f(x_j) \cdot h
= \frac{2 \pi}{n} \sum_{j=0}^{n-1} f(x_j)
= \frac{2 \pi}{n} \sum_{j=0}^{n-1} \left( a_0 + \sum_{k=1}^{+ \infty} a_k cos(k x_j)\right)
\]
Puisque la s\'erie converge, on peut intervertir les sommes :
\[
I_n = \frac{2 \pi}{n} \cdot n a_0 + \frac{2 \pi}{n} \sum_{k=1}^{+ \infty} \left( \sum_{j=0}^{n-1} a_k cos(k x_j) \right)
= 2 \pi a_0 + \frac{2 \pi}{n} \sum_{k=1}^{+ \infty} \left( a_k \sum_{j=0}^{n-1} cos(k x_j) \right)
\]
En remarquant que les $x_j = \frac{2 \pi j}{n}$ on a donc :
\[
I_n = 2 \pi a_0 + \frac{2 \pi}{n} \sum_{k=1}^{+ \infty} \left( \sum_{j=0}^{n-1} a_k cos\left( \frac{2 k j \pi }{n} \right) \right)
= 2 \pi a_0 + \frac{2 \pi}{n} \sum_{k=1}^{+ \infty} a_k S_{n,k}
\]
Ce qui conclut cette question.

\subsubsection{Partie b}

Posons $I= \int_{0}^{2 \pi} f(x) dx$. On s'int\'eresse \`a l'erreur $I_n - I$. On a d'un part :
\begin{align*}
I = &\int_{0}^{2 \pi} f(x) = \int_{0}^{2 \pi} \sum_{k=0}^{+ \infty} a_k cos(kx) dx
= \int_{0}^{2 \pi} a_0 + \sum_{k=1}^{+ \infty} a_k cos(kx) dx \\
=& \int_{0}^{2 \pi} a_0 dx + \int_{0}^{2 \pi} \sum_{k=}^{+ \infty} a_k cos(kx) dx
= 2 \pi a_0 + \sum_{k=1}^{+ \infty} \int_{0}^{2 \pi} a_k cos(kx) dx\\
=& 2 \pi a_0 + \sum_{k=1}^{+ \infty} {\left[ \frac{sin(kx)}{k} \right]}_0^{2\pi}
= 2 \pi a_0 + \sum_{k=1}^{+ \infty} 0 = 2 \pi a_0 + 0 = 2 \pi a_0
\end{align*}
L'interversion s\'erie int\'egrale est justifi\'ee car la s\'erie de Fourier converge uniform\'ement vers f. \\
D'autre part, on a par la question pr\'ec\'edente (et puisque la s\'erie converge) :
\[
\sum_{k=1}^{+ \infty} a_k S_{n,k} = \sum_{p=1}^{+ \infty} a_{pn} S_{n,pn}
= \sum_{p=1}^{+ \infty} a_{pn} \cdot n
= n \cdot \sum_{p=1}^{+ \infty} a_{pn}
\]
On en d\'eduit donc :
\begin{align*}
I_n - I =& I_n -  2 \pi a_0 = 2 \pi a_0 + \frac{2 \pi}{n} n \cdot \sum_{p=1}^{+ \infty} a_{pn} -  2 \pi a_0\\
=& 2 \pi \sum_{p=1}^{+ \infty} a_{pn}
\end{align*}
Ce qui conclut.

\subsubsection{Partie c}
On s'int\'eresse au comportement de la quantit\'e $I_n-I$ lorsque n tend vers l'infini. On peut encore une fois utiliser la convergence uniforme de la s\'erie de Fourier pour l'intervertion limite-s\'erie.

\begin{align*}
\lim_{n\to\infty} I_n-I  &=  \lim_{n\to\infty} 2 \pi \sum_{p=1}^{+ \infty} a_{pn} \\
&\leq \lim_{n\to\infty} 2 \pi \left \sum_{p=1}^{+ \infty} a_{pn} \right\\
&\leq \lim_{n\to\infty} 2 \pi \sum_{p=1}^{+ \infty}   a_{pn} \\
\end{align*}

Justifions l'utilisation du th\'eor\`eme de convergence domin\'ee. HELP.
L'interversion limite-s\'erie est donc bien justifi\'ee et on a : 
\begin{align*}
\lim_{n\to\infty}  I_n-I  &=2 \pi \sum_{p=1}^{+ \infty} \lim_{n\to\infty}  a_{pn}  \\
&= 2 \pi \sum_{p=1}^{+ \infty} 0 = 0
\end{align*}

\subsection{Question 3}

Supposons que f est de classe $\C^q$ (et v\'erifiant les autres hypoth`eses de l'\'enonc\'e. Les $a_k$ v\'erifient donc $a_k=\frac{\alpha_k}{n^q}$, o\`u $\alpha_k$ est une suite r\'elle tendant vers 0 lorsque k tend vers l'infini.
On a alors en particulier qu'il existe M r\'eel positif tel que : $|\alpha_k| \leq M$.\\
Cela nous donne que quel que soient p et n entiers positifs, on a : $|a_{pn}| \leq \frac{M}{(pn)^q}$
Et donc :
\begin{align*}
I_n - I =& 2 \pi \sum_{p=1}^{+ \infty} a_{pn}\\
\leq& 2 \pi \sum_{p=1}^{+ \infty} \frac{M}{(pn)^q}\\
\leq& \frac {2 \pi}{n^q}\sum_{p=1}^{+ \infty} \frac{M}{p^q}\\
\end{align*}
Puisque la s\'erie converge (s\'erie de Riemann) on a bien qu'il existe une constante r\'elle C telle que : $|I_n - I| \leq \frac{C}{n^q}$.

On peut interpr\'eter ce r\'esultat de la mani\`ere suivant : l'ordre de convergence de la m\'ethode des rectangles pour le type de fonction que nous \'etudions (paires et p\'eriodiques sur $[0;2 \pi]$) est \'egal \`a l'ordre q de la classe de r\'egulartit\'e de la fonction \'etudi\'ee.
\end{document}

\end{document}



